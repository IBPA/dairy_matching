{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import pickle as pkl \n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10,10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matching import row_corr, row_corr_weighted, match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCC_PATH = '/share/lemaylab-backedup/lactoseML/data/NCC_2018_nutrients_per_100g_originalcolnames.txt' \n",
    "\n",
    "ASA_PATH = '../data/training_for_GS_122118.csv' # for train data\n",
    "SUFFIX = 'train'\n",
    "\n",
    "# ASA_PATH = '/share/lemaylab-backedup/milklab/elizabeth/dairyML/testing_for_GS_122118.csv'  #fill in test data path here\n",
    "# SUFFIX='test'\n",
    "\n",
    "#ASA_PATH = '/share/lemaylab-backedup/milklab/elizabeth/dairyML/all_data_050719.csv' #both training and test data combined\n",
    "# SUFFIX = 'alldata'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the NCC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc = pd.read_csv(NCC_PATH,sep='\\t')\n",
    "\n",
    "ncc = ncc.rename(columns={'Food ID':'NCC Food ID'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from the ASA24 Recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "asa_24 = pd.read_csv(ASA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the file listing matching columns between the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = pd.read_csv('../data/matching_ncc_fndds_columns.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of columns for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc_cols = matching['NCC.Term'].values.tolist()\n",
    "asa_24_cols = matching['FNDDS.Term'].values.tolist()\n",
    "asa_24_cols = [val.replace(\" \",\"\") for val in asa_24_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the pairwise correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the columns provided by the `matching` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = asa_24.loc[:,asa_24_cols].values\n",
    "B = ncc.loc[:,ncc_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/lemaylab-backedup/lactoseML/scripts/matching.py:20: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  pcorr = ((p1 - p2)/np.sqrt(p3*p4[:,None]))\n",
      "/share/lemaylab-backedup/lactoseML/scripts/matching.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pcorr = ((p1 - p2)/np.sqrt(p3*p4[:,None]))\n"
     ]
    }
   ],
   "source": [
    "PCC_unweighted = row_corr(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate weighted pairwise correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the weights from the Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef = pd.read_csv('lasso_coef.csv')\n",
    "weights = lasso_coef.loc[:,'coef'].values[:-1] #omit 'year'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate weighted row-wise PCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/lemaylab-backedup/lactoseML/scripts/matching.py:31: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  pcorr = np.matmul(A,((B*w).T))/np.sqrt(np.matmul(((A**2)*w).sum(1)[:,None],(((B**2)*w).sum(1)[:,None]).T))\n",
      "/share/lemaylab-backedup/lactoseML/scripts/matching.py:31: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pcorr = np.matmul(A,((B*w).T))/np.sqrt(np.matmul(((A**2)*w).sum(1)[:,None],(((B**2)*w).sum(1)[:,None]).T))\n"
     ]
    }
   ],
   "source": [
    "PCC_weighted = row_corr_weighted(A,B,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarity between labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the food names, remove delimiting characters and set to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_labels = asa_24.Food_Description.values\n",
    "\n",
    "B_labels = ncc['Short Food Description'].values\n",
    "\n",
    "A_labels = [re.sub('[.\\/#!$%\\^&\\*;:{}=\\-_`~()]','',label).lower() for label in A_labels]\n",
    "B_labels = [re.sub('[.\\/#!$%\\^&\\*;:{}=\\-_`~()]','',label).lower() for label in B_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "Compute the tf-idf vector for each label, then match labels based on cosine similarity. tf-idf stands for Term Frequency-Inverse Document Frequency. In this case it is used to generate a unique numerical vector that is representative of the text content in each label.\n",
    "\n",
    "N-gram code and inspiration from: https://bergvca.github.io/2017/10/14/super-fast-string-matching.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to generate all n-grams from each label, to be used as analyzer in tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=3):\n",
    "    comma_sep_chunks = [tok.strip() for tok in string.split(',')]\n",
    "    string = ' '.join([comma_sep_chunks[0]] + comma_sep_chunks)\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams] + comma_sep_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the labels from A (ASA24) and B (NCC) datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = A_labels + B_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit tf-idf vectorizer to the full set of labels, compute tf-idf vectors for A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "vectorizer.fit(all_labels)\n",
    "tf_idf_A = vectorizer.transform(A_labels)\n",
    "tf_idf_B = vectorizer.transform(B_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute similarity matrix between A and B labels using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_sim = np.array(cosine_similarity(tf_idf_A,tf_idf_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get results (unweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_top = {}\n",
    "results_top_desc_only = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the tf-idf similarity and pcc similarity matrices using element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCC_TFIDF_unweighted = np.multiply(tf_idf_sim,PCC_unweighted)\n",
    "PCC_TFIDF_weighted = np.multiply(tf_idf_sim,PCC_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/4.5.12/lssc0-linux/lib/python3.6/site-packages/scipy/stats/stats.py:1025: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return a.std(axis) / a.mean(axis)\n"
     ]
    }
   ],
   "source": [
    "results_top['PCC_unweighted'] = match(PCC_unweighted,asa_24,ncc,TOP)\n",
    "results_top['PCC_weighted'] = match(PCC_weighted,asa_24,ncc,TOP)\n",
    "results_top['PCC_TFIDF_unweighted'] = match(PCC_TFIDF_unweighted,asa_24,ncc,TOP)\n",
    "results_top['PCC_TFIDF_weighted'] = match(PCC_TFIDF_weighted,asa_24,ncc,TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce results to description only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_only_cols = ['FoodCode','Food_Description','year','lac.per.100g','similarity','NCC Food ID','Keylist','Food Description','Short Food Description','Food Type','Lactose (g)','variation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results_top.keys():\n",
    "    results_top_desc_only[key] = results_top[key][desc_only_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in results_top.items():\n",
    "    name = key+'_matching_results_top_{}_'.format(TOP)+SUFFIX+'.tsv'\n",
    "    path = '../data/' + name\n",
    "    df.to_csv(path,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in results_top_desc_only.items():\n",
    "    name = key+'_matching_results_top_{}_desc_only_'.format(TOP)+SUFFIX+'.tsv'\n",
    "    path = '../data/' + name\n",
    "    df.to_csv(path,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get first matches only in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_matches = results_top.loc[(results_top_desc_only.index.get_level_values('match_index') == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column indicating the error between matched and labelled lactose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_matches['error'] = abs(first_matches['lac.per.100g'] - first_matches['Lactose (g)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the first matches, sorted by error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_matches[desc_only_cols + ['error']].sort_values('error',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute error measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # labeled_lactose = results_top.loc[:,'lac.per.100g']\n",
    "# # labeled_lactose = labeled_lactose[~np.isnan(labeled_lactose)].values()\n",
    "\n",
    "# labeled_lactose_first = first_matches['lac.per.100g']\n",
    "# lookup_lactose_first = first_matches['Lactose (g)']\n",
    "# lookup_lactose_mean_top = pd.DataFrame(results_top['Lactose (g)'].groupby(\"asa_index\").apply(np.mean)).values.flatten()\n",
    "# # labeled_lactose_nonzero = labeled_lactose[labeled_lactose != 0]\n",
    "# # lookup_lactose_nonzero = lookup_lactose[labeled_lactose != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_absolute_percentage_error_nz(y_true, y_pred): \n",
    "#     \"\"\"Compute mean absolute percentage error (MAPE) between actual and predicted vectors, where actual is nonzero\"\"\"\n",
    "#     y_true_nz = y_true[y_true != 0]\n",
    "#     y_pred_nz = y_pred[y_true != 0]\n",
    "#     return np.mean(np.abs((y_true_nz - y_pred_nz) / y_true_nz)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score(actual,pred):\n",
    "#     \"\"\"compute and display MAE, MAPE, R2 between actual and predicted vectors\"\"\"\n",
    "#     print('MAE: {}'.format(round(mean_absolute_error(actual,pred),2)))\n",
    "#     print('MAPE: {}'.format(round(mean_absolute_percentage_error_nz(actual,pred),2)))\n",
    "#     print('R2: {}'.format(round(r2_score(actual,pred),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.48\n",
      "MAPE: 209.51\n",
      "R2: 0.77\n"
     ]
    }
   ],
   "source": [
    "# score(labeled_lactose_first,lookup_lactose_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of top 5 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.87\n",
      "MAPE: 298.3\n",
      "R2: 0.61\n"
     ]
    }
   ],
   "source": [
    "# score(labeled_lactose_first,lookup_lactose_mean_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual vs Predicted plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_results(actual,pred,title):\n",
    "#     \"\"\"actual vs. predicted plot\"\"\"\n",
    "#     plt.scatter(x=actual,y=pred,s=3)\n",
    "#     plt.xlabel('Dietitian-selected value')\n",
    "#     plt.ylabel('Matched value')\n",
    "#     plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_results(labeled_lactose_first,lookup_lactose_first,'dietitian selected vs. first match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_results(labeled_lactose_first,lookup_lactose_mean_top,'dietitian selected vs. mean of top 5 matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
